{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POTATO Take-Home Task\\nOverview:\\nPOTATO (the Panel-based Open Term-level Aggregate Twitter Observatory) is a prototype website that uses data \\nfrom the Lazer Lab’s Twitter Panel. The Twitter Panel links over one million real U.S. voters to their Twitter \\naccounts, and has each panelist’s tweets from about 2016 until 2023 or so. POTATO will allow users to search \\nfor a term (“COVID”) and get aggregate information about the people who tweeted about the term. We will \\nthreshold results such that any demographic bucket with fewer than ten users will not be shown; we’re also \\nconsidering using statistical processes to add noise without disrupting the overall distribution of the data. \\nRight now the system uses Docker, Elasticsearch, Streamlit, and Python. Our biggest technical problems are a) \\ningesting the data from HDFS efficiently and b) returning results quickly. We also need to look into \\nstrengthening our privacy protections.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LINK - https://drive.google.com/drive/folders/1GY_-vRTkAdx7i7Sp4ZbCfO2yiG-iSNRJ\n",
    "# I used the 50 MB dataset\n",
    "\n",
    "\"\"\"POTATO Take-Home Task\n",
    "Overview:\n",
    "POTATO (the Panel-based Open Term-level Aggregate Twitter Observatory) is a prototype website that uses data \n",
    "from the Lazer Lab’s Twitter Panel. The Twitter Panel links over one million real U.S. voters to their Twitter \n",
    "accounts, and has each panelist’s tweets from about 2016 until 2023 or so. POTATO will allow users to search \n",
    "for a term (“COVID”) and get aggregate information about the people who tweeted about the term. We will \n",
    "threshold results such that any demographic bucket with fewer than ten users will not be shown; we’re also \n",
    "considering using statistical processes to add noise without disrupting the overall distribution of the data. \n",
    "Right now the system uses Docker, Elasticsearch, Streamlit, and Python. Our biggest technical problems are a) \n",
    "ingesting the data from HDFS efficiently and b) returning results quickly. We also need to look into \n",
    "strengthening our privacy protections.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ingest the data: figure out a way to put the data in a structure so that you can query it as described in Part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>from_stream</th>\n",
       "      <th>directly_from_stream</th>\n",
       "      <th>from_search</th>\n",
       "      <th>directly_from_search</th>\n",
       "      <th>from_quote_search</th>\n",
       "      <th>directly_from_quote_search</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_author_id</th>\n",
       "      <th>retweeted_handle</th>\n",
       "      <th>retweeted_follower_count</th>\n",
       "      <th>mentioned_author_ids</th>\n",
       "      <th>mentioned_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>media_keys</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131594960443199488</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131594976750653440</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1131589737955942405</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131594909469892610</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1131594812694511617</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1.130918e+18</td>\n",
       "      <td>3.042894e+09</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           event                               ts1  \\\n",
       "0  1131594960443199488  britney_201904  2022-02-28 09:34:44.627023-05:00   \n",
       "1  1131594976750653440  britney_201904  2022-02-28 09:34:44.626921-05:00   \n",
       "2  1131589737955942405  britney_201904  2022-02-28 09:34:44.634058-05:00   \n",
       "3  1131594909469892610  britney_201904  2022-02-28 09:34:44.627125-05:00   \n",
       "4  1131594812694511617  britney_201904  2022-02-28 09:34:44.627227-05:00   \n",
       "\n",
       "                                ts2  from_stream  directly_from_stream  \\\n",
       "0  2022-02-28 09:34:44.627023-05:00         True                  True   \n",
       "1  2022-02-28 09:34:44.626921-05:00         True                  True   \n",
       "2  2022-02-28 09:34:44.634058-05:00         True                  True   \n",
       "3  2022-02-28 09:34:44.627125-05:00         True                  True   \n",
       "4  2022-02-28 09:34:44.627227-05:00         True                  True   \n",
       "\n",
       "   from_search  directly_from_search  from_quote_search  \\\n",
       "0        False                 False              False   \n",
       "1        False                 False              False   \n",
       "2        False                 False              False   \n",
       "3        False                 False              False   \n",
       "4        False                 False              False   \n",
       "\n",
       "   directly_from_quote_search  ...     retweeted  retweeted_author_id  \\\n",
       "0                       False  ...  1.130918e+18         3.042894e+09   \n",
       "1                       False  ...           NaN                  NaN   \n",
       "2                       False  ...           NaN                  NaN   \n",
       "3                       False  ...  1.130918e+18         3.042894e+09   \n",
       "4                       False  ...  1.130918e+18         3.042894e+09   \n",
       "\n",
       "   retweeted_handle  retweeted_follower_count mentioned_author_ids  \\\n",
       "0          Iesbwian                   22760.0                  NaN   \n",
       "1               NaN                       NaN                  NaN   \n",
       "2               NaN                       NaN                  NaN   \n",
       "3          Iesbwian                   22760.0                  NaN   \n",
       "4          Iesbwian                   22760.0                  NaN   \n",
       "\n",
       "  mentioned_handles  hashtags urls media_keys  place_id  \n",
       "0               NaN       NaN  NaN        NaN       NaN  \n",
       "1               NaN       NaN  NaN        NaN       NaN  \n",
       "2               NaN       NaN  NaN        NaN       NaN  \n",
       "3               NaN       NaN  NaN        NaN       NaN  \n",
       "4               NaN       NaN  NaN        NaN       NaN  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import warnings as warn\n",
    "warn.filterwarnings(\"ignore\")\n",
    "import pandas as pd \n",
    "\n",
    "# We will load the tweet data into a Pandas DataFrame. \n",
    "twitter_ = pd.read_csv(\"C:\\Python programming\\correct_twitter_201904.tsv\", sep=\"\\t\")\n",
    "twitter_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'id' column is unique, no duplicate present\n"
     ]
    }
   ],
   "source": [
    "# drop_duplicated row\n",
    "# Checking the ID column whether it contain any duplicate row or not\n",
    "print(\"'id' column is unique, no duplicate present\") if twitter_.duplicated(subset=\"id\", keep=\"first\").sum() == 0 else \\\n",
    "    print(\"ID column is not unique\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88037 entries, 0 to 88036\n",
      "Data columns (total 46 columns):\n",
      " #   Column                         Non-Null Count  Dtype  \n",
      "---  ------                         --------------  -----  \n",
      " 0   id                             88037 non-null  int64  \n",
      " 1   event                          88037 non-null  object \n",
      " 2   ts1                            88037 non-null  object \n",
      " 3    ts2                           88037 non-null  object \n",
      " 4   from_stream                    88037 non-null  bool   \n",
      " 5   directly_from_stream           88037 non-null  bool   \n",
      " 6   from_search                    88037 non-null  bool   \n",
      " 7   directly_from_search           88037 non-null  bool   \n",
      " 8   from_quote_search              88037 non-null  bool   \n",
      " 9   directly_from_quote_search     88037 non-null  bool   \n",
      " 10  from_convo_search              88037 non-null  bool   \n",
      " 11  directly_from_convo_search     88037 non-null  bool   \n",
      " 12  from_timeline_search           88037 non-null  bool   \n",
      " 13  directly_from_timeline_search  88037 non-null  bool   \n",
      " 14  text                           88037 non-null  object \n",
      " 15  lang                           88037 non-null  object \n",
      " 16  author_id                      88037 non-null  int64  \n",
      " 17  author_handle                  88037 non-null  object \n",
      " 18  created_at                     88037 non-null  object \n",
      " 19  conversation_id                88037 non-null  int64  \n",
      " 20  possibly_sensitive             88037 non-null  bool   \n",
      " 21  reply_settings                 88037 non-null  object \n",
      " 22  source                         88037 non-null  object \n",
      " 23  author_follower_count          88037 non-null  int64  \n",
      " 24  retweet_count                  88037 non-null  int64  \n",
      " 25  reply_count                    88037 non-null  int64  \n",
      " 26  like_count                     88037 non-null  int64  \n",
      " 27  quote_count                    88037 non-null  int64  \n",
      " 28  replied_to                     6675 non-null   float64\n",
      " 29  replied_to_author_id           3850 non-null   float64\n",
      " 30  replied_to_handle              3684 non-null   object \n",
      " 31  replied_to_follower_count      3850 non-null   float64\n",
      " 32  quoted                         2052 non-null   float64\n",
      " 33  quoted_author_id               1776 non-null   float64\n",
      " 34  quoted_handle                  1629 non-null   object \n",
      " 35  quoted_follower_count          1776 non-null   float64\n",
      " 36  retweeted                      51529 non-null  float64\n",
      " 37  retweeted_author_id            51529 non-null  float64\n",
      " 38  retweeted_handle               51529 non-null  object \n",
      " 39  retweeted_follower_count       51529 non-null  float64\n",
      " 40  mentioned_author_ids           0 non-null      float64\n",
      " 41  mentioned_handles              0 non-null      float64\n",
      " 42  hashtags                       12162 non-null  object \n",
      " 43  urls                           41641 non-null  object \n",
      " 44  media_keys                     16512 non-null  object \n",
      " 45  place_id                       1021 non-null   object \n",
      "dtypes: bool(11), float64(11), int64(8), object(16)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Checking the information\n",
    "twitter_.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'event', 'ts1', 'ts2', 'from_stream', 'directly_from_stream',\n",
       "       'from_search', 'directly_from_search', 'from_quote_search',\n",
       "       'directly_from_quote_search', 'from_convo_search',\n",
       "       'directly_from_convo_search', 'from_timeline_search',\n",
       "       'directly_from_timeline_search', 'text', 'lang', 'author_id',\n",
       "       'author_handle', 'created_at', 'conversation_id', 'possibly_sensitive',\n",
       "       'reply_settings', 'source', 'author_follower_count', 'retweet_count',\n",
       "       'reply_count', 'like_count', 'quote_count', 'replied_to',\n",
       "       'replied_to_author_id', 'replied_to_handle',\n",
       "       'replied_to_follower_count', 'quoted', 'quoted_author_id',\n",
       "       'quoted_handle', 'quoted_follower_count', 'retweeted',\n",
       "       'retweeted_author_id', 'retweeted_handle', 'retweeted_follower_count',\n",
       "       'mentioned_author_ids', 'mentioned_handles', 'hashtags', 'urls',\n",
       "       'media_keys', 'place_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Columns aligment\n",
    "twitter_.columns = twitter_.columns.str.strip()\n",
    "\n",
    "twitter_.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the 'ts1', 'ts2' into timestamp\n",
    "twitter_[\"ts1\"] = pd.to_datetime(twitter_[\"ts1\"])\n",
    "twitter_[\"ts2\"] = pd.to_datetime(twitter_[\"ts2\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construct functionality that allows you to query the data. If I search for a term, like “music,” I would like to know some subset of the following:\n",
    "#### - How many tweets were posted containing the term on each day?\n",
    "#### - How many unique users posted a tweet containing the term?\n",
    "#### - How many likes did tweets containing the term get, on average?\n",
    "#### - Where (in terms of place IDs) did the tweets come from?\n",
    "#### - What times of day were the tweets posted at? \n",
    "#### - Which user posted the most tweets containing the term?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "term is 'music'\n",
      "question1 : How many tweets were posted containing the term on each day?\n",
      "         date  tweet_count\n",
      "0  2022-01-04           66\n",
      "1  2022-02-28         2935\n",
      "\n",
      "question2 : How many unique users posted a tweet containing the term?\n",
      "2109\n",
      "\n",
      "question3 : How many likes did tweets containing the term get, on average?\n",
      "161.40853048983672\n",
      "\n",
      "question4 : Where (in terms of place IDs) did the tweets come from?\n",
      "['53504716d445dcad' 'ab2f2fac83aa388d' '0113afc024d5e0bc'\n",
      " '300bcc6e23a88361' '8e9665cec9370f0f' 'd56c5babcffde8ef'\n",
      " '01153d1b33e1641b' '09f6a7707f18e0b1' '714789cf3b7a50d0'\n",
      " '01fbe706f872cb32' '1a7a70d4a28e96a1' 'f97108ab3c4a42ed'\n",
      " 'ac88a4f17a51c7fc' '5de8cffc145c486b' '3f7a925ec706ea48'\n",
      " '001aff55522d96c9' '4c8e28554110ebcf' '5c62ffb0f0f3479d'\n",
      " '3b77caf94bfc81fe' 'ecbe2aea853af44e' 'de599025180e2ee7'\n",
      " '00b673715a35dfa7' '43d2418301bf1a49' '07e9c7d1954fff64'\n",
      " '0570f015c264cbd9' '0149775319466b18' '91890dbb74364d63'\n",
      " '01ddb0100b1efd97' 'b49b3053b5c25bf5' '7cb7440bcf83d464'\n",
      " '151b9e91272233d1' '9d63050d3d33d32f' '140800566259f12f'\n",
      " '743df94d8dcb69a6' '8bc4eeacf63235f9' '8943f93b51e3f357'\n",
      " '2bc7c264a080898b' '814cfc71b843ff40' '2b8922cbe7f16337'\n",
      " '7de31e05e99a00f8']\n",
      "\n",
      "question5 : What times of day were the tweets posted at? \n",
      "              time  tweet_count\n",
      "0  09:34:49.489632            1\n",
      "1  09:43:47.825242            1\n",
      "2  09:43:47.821944            1\n",
      "3  09:43:47.822094            1\n",
      "4  09:43:47.822347            1\n",
      "\n",
      "Question6 : Which user posted the most tweets containing the term?\n",
      "(118301422, 90)\n"
     ]
    }
   ],
   "source": [
    "class Twitter_Tweets:\n",
    "    \n",
    "    def __init__(self, term):\n",
    "        self.term = term\n",
    "\n",
    "    def count_tweets_by_day(self):\n",
    "        \"\"\"\n",
    "        Count the number of tweets containing a term on each day.\n",
    "\n",
    "        Parameters:\n",
    "        term (str): The term to search for in tweets.\n",
    "\n",
    "        Returns:\n",
    "        DataFrame: A DataFrame with dates and tweet counts.\n",
    "        \"\"\"\n",
    "        # Filter for tweets containing the term\n",
    "        filtered_df1 = twitter_[twitter_['text'].str.contains(self.term, case=False, na=False)]\n",
    "\n",
    "        # Extract the date from the timestamp\n",
    "        filtered_df1['date'] = filtered_df1['ts1'].dt.date\n",
    "\n",
    "        # Group by date and count\n",
    "        tweet_counts = filtered_df1.groupby('date').size().reset_index(name='tweet_count')\n",
    "\n",
    "        return tweet_counts\n",
    "    \n",
    "    def count_unique_users_by_term(self):\n",
    "        # Filter for tweets containing the term\n",
    "        filtered_df = twitter_[\n",
    "            twitter_['text'].str.contains(self.term, case=False, na=False)\n",
    "        ]\n",
    "\n",
    "        # Count unique users\n",
    "        unique_count = filtered_df['author_id'].nunique()\n",
    "\n",
    "        return unique_count\n",
    "    \n",
    "    def average_likes_by_term(self):\n",
    "        # Filter for tweets containing the term\n",
    "        filtered_df03 = twitter_[\n",
    "            twitter_['text'].str.contains(self.term, case=False, na=False)\n",
    "        ]\n",
    "\n",
    "        # Calculate the average likes\n",
    "        if filtered_df03.empty:\n",
    "            avg_likes = 0\n",
    "        else:\n",
    "            avg_likes = filtered_df03['like_count'].mean()\n",
    "\n",
    "        return avg_likes\n",
    "    \n",
    "    def places_of_tweets_by_term(self):\n",
    "        # Filter for tweets containing the term\n",
    "        filtered_df = twitter_[\n",
    "            twitter_['text'].str.contains(self.term, case=False, na=False)\n",
    "        ]\n",
    "\n",
    "        # Get the unique place IDs\n",
    "        unique_place_ids = filtered_df['place_id'].dropna().unique()  # Drop NaN values\n",
    "\n",
    "        return unique_place_ids\n",
    "    \n",
    "    def times_of_day_by_term(self):\n",
    "        # Filter for tweets containing the term \"music\"\n",
    "        filtered_df = twitter_[twitter_['text'].str.contains(self.term, case=False, na=False)]\n",
    "\n",
    "        # Extract the time from the timestamp\n",
    "        filtered_df['time'] = filtered_df['ts1'].dt.time\n",
    "\n",
    "        ## value count and convert it as dataframe\n",
    "        time_counts = filtered_df['time'].value_counts().reset_index(name='tweet_count')\n",
    "\n",
    "        ## changing the columns name\n",
    "        time_counts.columns = ['time', 'tweet_count']\n",
    "\n",
    "        return time_counts\n",
    "    \n",
    "    def most_active_user_by_term(self):\n",
    "        # Filter for tweets containing the term \"music\"\n",
    "        filtered_df = twitter_[twitter_['text'].str.contains(self.term, case=False, na=False)]\n",
    "\n",
    "        # Checking for Tweets:\n",
    "        if filtered_df.empty:\n",
    "            return 0  # No tweets found\n",
    "        \n",
    "        # Counting Author IDs : \n",
    "        \"\"\"returns the author_id that has the highest count, which corresponds to the most active user.\"\"\"\n",
    "        most_active_user = filtered_df['author_id'].value_counts().idxmax()\n",
    "        tweet_count = filtered_df['author_id'].value_counts().max()\n",
    "        return most_active_user, tweet_count\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "print(\"term is 'music'\")\n",
    "term = input(\"Enter the tweet term : \")\n",
    "\n",
    "print(\"question1 : How many tweets were posted containing the term on each day?\")\n",
    "# question 1\n",
    "## How many tweets were posted containing the term on each day?\n",
    "result1 = Twitter_Tweets(term=term)\n",
    "print(result1.count_tweets_by_day())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"question2 : How many unique users posted a tweet containing the term?\")\n",
    "# question 2 \n",
    "## How many unique users posted a tweet containing the term?\n",
    "result2 = Twitter_Tweets(term=term)\n",
    "print(result2.count_unique_users_by_term())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"question3 : How many likes did tweets containing the term get, on average?\")\n",
    "result3 = Twitter_Tweets(term=term)\n",
    "print(result3.average_likes_by_term())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"question4 : Where (in terms of place IDs) did the tweets come from?\")\n",
    "result4 = Twitter_Tweets(term=term)\n",
    "print(result4.places_of_tweets_by_term())\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"question5 : What times of day were the tweets posted at? \")\n",
    "result5 = Twitter_Tweets(term=term)\n",
    "print(result5.times_of_day_by_term().head())\n",
    "\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"Question6 : Which user posted the most tweets containing the term?\")\n",
    "result6 = Twitter_Tweets(term=term)\n",
    "print(result6.most_active_user_by_term())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
